import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
from io import BytesIO

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã Streamlit ---
st.set_page_config(
    page_title="–§–∏–Ω–∞–ª—å–Ω—ã–π –ü–ª–∞–Ω/–§–∞–∫—Ç –ê–Ω–∞–ª–∏–∑ v7.0",
    page_icon="üèÜ",
    layout="wide"
)

st.title("üèÜ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è –ü–ª–∞–Ω/–§–∞–∫—Ç –∞–Ω–∞–ª–∏–∑–∞")

# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö ---

@st.cache_data
def analyze_data_quality(df, file_name):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –≤ DataFrame."""
    quality_info = []
    if df is None or df.empty:
        return pd.DataFrame()
    total_rows = len(df)
    for col in df.columns:
        non_null_count = df[col].notna().sum()
        null_count = total_rows - non_null_count
        quality_info.append({
            '–§–∞–π–ª': file_name,
            '–ö–æ–ª–æ–Ω–∫–∞': col,
            '–ó–∞–ø–æ–ª–Ω–µ–Ω–æ': non_null_count,
            '–ü—É—Å—Ç—ã–µ': null_count,
            '–ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è': f"{(non_null_count/total_rows*100):.1f}%"
        })
    return pd.DataFrame(quality_info)

@st.cache_data
def transform_wide_to_flat(_wide_df, id_vars):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —à–∏—Ä–æ–∫–∏–π DataFrame –ø–ª–∞–Ω–∞ –≤ –ø–ª–æ—Å–∫–∏–π."""
    plan_data_cols = [col for col in _wide_df.columns if col not in id_vars]
    magazin_cols = sorted([col for col in plan_data_cols if col.split('.')[0] == 'Magazin'])
    stuki_cols = sorted([col for col in plan_data_cols if col.split('.')[0] == 'Plan_STUKI'])
    grn_cols = sorted([col for col in plan_data_cols if col.split('.')[0] == 'Plan_GRN'])

    if not (len(magazin_cols) == len(stuki_cols) == len(grn_cols) and len(magazin_cols) > 0):
        st.error("–û—à–∏–±–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–∞ –ü–ª–∞–Ω–∞: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ª–æ–Ω–æ–∫ 'Magazin', 'Plan_STUKI' –∏ 'Plan_GRN' –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –∏–ª–∏ —Ä–∞–≤–Ω–æ –Ω—É–ª—é.")
        return None
        
    flat_parts = []
    for i in range(len(magazin_cols)):
        current_cols = id_vars + [magazin_cols[i], stuki_cols[i], grn_cols[i]]
        part_df = _wide_df[current_cols].copy()
        part_df.rename(columns={magazin_cols[i]: '–º–∞–≥–∞–∑–∏–Ω', stuki_cols[i]: 'Plan_STUKI', grn_cols[i]: 'Plan_GRN'}, inplace=True)
        flat_parts.append(part_df)
        
    flat_df = pd.concat(flat_parts, ignore_index=True)
    flat_df.dropna(subset=['–º–∞–≥–∞–∑–∏–Ω'], inplace=True)
    return flat_df

@st.cache_data
def calculate_metrics(df):
    """–†–∞—Å—á–µ—Ç –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ –¥–ª—è –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–≥–æ DataFrame."""
    metrics = {}
    metrics['total_plan_qty'] = df['Plan_STUKI'].sum()
    metrics['total_fact_qty'] = df['Fact_STUKI'].sum()
    metrics['total_plan_money'] = df['Plan_GRN'].sum()
    metrics['total_fact_money'] = df['Fact_GRN'].sum()
    metrics['qty_deviation'] = metrics['total_fact_qty'] - metrics['total_plan_qty']
    metrics['money_deviation'] = metrics['total_fact_money'] - metrics['total_plan_money']
    metrics['qty_completion'] = (metrics['total_fact_qty'] / metrics['total_plan_qty'] * 100) if metrics['total_plan_qty'] > 0 else 0
    metrics['money_completion'] = (metrics['total_fact_money'] / metrics['total_plan_money'] * 100) if metrics['total_plan_money'] > 0 else 0
    return metrics

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Session State ---
if 'processed_df' not in st.session_state:
    st.session_state.processed_df = None

# --- –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ ---
st.header("1. –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤")
col1, col2 = st.columns(2)
with col1:
    plan_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª '–ü–ª–∞–Ω'", type=["xlsx", "xls"], key="plan_uploader")
with col2:
    fact_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª '–§–∞–∫—Ç'", type=["xlsx", "xls"], key="fact_uploader")

if plan_file and fact_file:
    plan_df_original = pd.read_excel(plan_file)
    fact_df_original = pd.read_excel(fact_file)
    
    with st.expander("1.1. –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö", expanded=False):
        plan_quality = analyze_data_quality(plan_df_original, "–ü–ª–∞–Ω")
        fact_quality = analyze_data_quality(fact_df_original, "–§–∞–∫—Ç")
        quality_df = pd.concat([plan_quality, fact_quality], ignore_index=True)
        st.dataframe(quality_df, use_container_width=True)

    st.header("2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    
    with st.form("processing_form"):
        plan_format = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ '–ü–ª–∞–Ω':", ('–ü–ª–æ—Å–∫–∏–π (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π)', '–®–∏—Ä–æ–∫–∏–π (–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π)'), horizontal=True)
        
        plan_mappings = {}
        id_vars = []

        if plan_format == '–®–∏—Ä–æ–∫–∏–π (–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π)':
            st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è —à–∏—Ä–æ–∫–æ–≥–æ —Ñ–∞–π–ª–∞ '–ü–ª–∞–Ω'")
            all_plan_columns = plan_df_original.columns.tolist()
            id_vars = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏, –æ–ø–∏—Å—ã–≤–∞—é—â–∏–µ —Ç–æ–≤–∞—Ä:", options=all_plan_columns,
                                     default=[col for col in ['ART', 'Describe', 'MOD', 'Price', 'Brend', 'Segment'] if col in all_plan_columns])
        else:
            st.subheader("–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –ø–ª–æ—Å–∫–æ–≥–æ —Ñ–∞–π–ª–∞ '–ü–ª–∞–Ω'")
            PLAN_REQUIRED_FIELDS = {'–º–∞–≥–∞–∑–∏–Ω': '–ú–∞–≥–∞–∑–∏–Ω', 'ART': '–ê—Ä—Ç–∏–∫—É–ª', 'Describe': '–û–ø–∏—Å–∞–Ω–∏–µ', 'MOD': '–ú–æ–¥–µ–ª—å', 'Price': '–¶–µ–Ω–∞', 'brend': '–ë—Ä–µ–Ω–¥', 'Segment': '–°–µ–≥–º–µ–Ω—Ç', 'Plan_STUKI': '–û—Å—Ç–∞—Ç–∫–∏-–ü–ª–∞–Ω (—à—Ç.)', 'Plan_GRN': '–û—Å—Ç–∞—Ç–∫–∏ –≤ –¥–µ–Ω—å–≥–∞—Ö (–ø–ª–∞–Ω)'}
            for internal, display in PLAN_REQUIRED_FIELDS.items():
                plan_mappings[internal] = st.selectbox(f'"{display}"', [''] + plan_df_original.columns.tolist(), key=f'plan_{internal}')
        
        st.subheader("–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è —Ñ–∞–π–ª–∞ '–§–∞–∫—Ç'")
        fact_mappings = {}
        fact_cols = fact_df_original.columns.tolist()
        FACT_REQUIRED_FIELDS = {'–º–∞–≥–∞–∑–∏–Ω': '–ú–∞–≥–∞–∑–∏–Ω', 'ART': '–ê—Ä—Ç–∏–∫—É–ª', 'Describe': '–û–ø–∏—Å–∞–Ω–∏–µ', 'MOD': '–ú–æ–¥–µ–ª—å', 'brend': '–ë—Ä–µ–Ω–¥', 'Fact_STUKI': '–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å—Ç–∞—Ç–∫–∏ (—à—Ç.)'}
        for internal, display in FACT_REQUIRED_FIELDS.items():
            fact_mappings[internal] = st.selectbox(f'"{display}"', [''] + fact_cols, key=f'fact_{internal}')
            
        submitted = st.form_submit_button("üöÄ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑", type="primary")

    if submitted:
        try:
            if plan_format == '–®–∏—Ä–æ–∫–∏–π (–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π)':
                if not id_vars: st.error("–î–ª—è —à–∏—Ä–æ–∫–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–±—Ä–∞—Ç—å –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏."); st.stop()
                plan_df = transform_wide_to_flat(plan_df_original, id_vars)
                # –î–ª—è —à–∏—Ä–æ–∫–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –Ω–∞–º –Ω—É–∂–Ω–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ 'Brend' -> 'brend'
                if 'Brend' in plan_df.columns:
                    plan_df = plan_df.rename(columns={'Brend': 'brend'})
            else:
                plan_rename_map = {v: k for k, v in plan_mappings.items() if v != ''}
                if len(plan_rename_map) != len(PLAN_REQUIRED_FIELDS): st.error("–ù–µ –≤—Å–µ –ø–æ–ª—è –¥–ª—è —Ñ–∞–π–ª–∞ '–ü–ª–∞–Ω' —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω—ã."); st.stop()
                plan_df = plan_df_original[list(plan_rename_map.keys())].rename(columns=plan_rename_map)

            if plan_df is None: st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª '–ü–ª–∞–Ω'."); st.stop()
            
            fact_rename_map = {v: k for k, v in fact_mappings.items() if v != ''}
            if len(fact_rename_map) != len(FACT_REQUIRED_FIELDS): st.error("–ù–µ –≤—Å–µ –ø–æ–ª—è –¥–ª—è —Ñ–∞–π–ª–∞ '–§–∞–∫—Ç' —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω—ã."); st.stop()
            fact_df = fact_df_original[list(fact_rename_map.keys())].rename(columns=fact_rename_map)

            merge_keys = ['–º–∞–≥–∞–∑–∏–Ω', 'ART', 'Describe', 'MOD']
            for key in merge_keys:
                if key in plan_df.columns and key in fact_df.columns:
                    plan_df[key], fact_df[key] = plan_df[key].astype(str), fact_df[key].astype(str)
            
            # –í —Ñ–∞–π–ª–µ —Ñ–∞–∫—Ç–∞ –º–æ–∂–µ—Ç –Ω–µ –±—ã—Ç—å –≤—Å–µ—Ö –∫–æ–ª–æ–Ω–æ–∫, –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ –µ—Å—Ç—å –≤ –æ–±–æ–∏—Ö
            final_merge_keys = [key for key in merge_keys if key in plan_df.columns and key in fact_df.columns]
            
            # –ò–∑ –ø–ª–∞–Ω–∞ –±–µ—Ä–µ–º –µ—â–µ –∏ 'brend', 'Segment', 'Price'
            plan_cols_to_merge = final_merge_keys + [col for col in ['brend', 'Segment', 'Price', 'Plan_STUKI', 'Plan_GRN'] if col in plan_df.columns]
            
            # –ò–∑ —Ñ–∞–∫—Ç–∞ - —Ç–æ–ª—å–∫–æ –∫–ª—é—á–∏ –∏ —à—Ç—É–∫–∏
            fact_cols_to_merge = final_merge_keys + ['Fact_STUKI']
            
            merged_df = pd.merge(plan_df[plan_cols_to_merge], fact_df[fact_cols_to_merge], on=final_merge_keys, how='outer')

            columns_to_fill = ['Plan_STUKI', 'Fact_STUKI', 'Plan_GRN', 'Price']
            for col in columns_to_fill:
                 if col in merged_df.columns:
                    merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce').fillna(0)
            
            merged_df['Fact_GRN'] = merged_df['Fact_STUKI'] * merged_df['Price']
            merged_df['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_—à—Ç'] = merged_df['Fact_STUKI'] - merged_df['Plan_STUKI']
            merged_df['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_–≥—Ä–Ω'] = merged_df['Fact_GRN'] - merged_df['Plan_GRN']
            
            st.session_state.processed_df = merged_df
            st.success("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
        except Exception as e:
            st.session_state.processed_df = None; st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")

if st.session_state.processed_df is not None:
    processed_df = st.session_state.processed_df
    
    st.header("3. –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞–º")
    store_summary = processed_df.groupby('–º–∞–≥–∞–∑–∏–Ω').agg(Plan_STUKI=('Plan_STUKI', 'sum'), Fact_STUKI=('Fact_STUKI', 'sum'), Plan_GRN=('Plan_GRN', 'sum'), Fact_GRN=('Fact_GRN', 'sum')).reset_index()
    store_summary['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_—à—Ç'] = store_summary['Fact_STUKI'] - store_summary['Plan_STUKI']
    store_summary['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_%_—à—Ç'] = np.where(store_summary['Plan_STUKI'] > 0, abs(store_summary['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_—à—Ç']) / store_summary['Plan_STUKI'] * 100, np.inf)
    threshold = st.number_input("–ü–æ—Ä–æ–≥ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –≤ —à—Ç—É–∫–∞—Ö (%)", value=10, min_value=0, max_value=1000)
    problem_stores_df = store_summary[store_summary['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_%_—à—Ç'] > threshold].sort_values('–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_%_—à—Ç', ascending=False)
    st.write(f"**–ù–∞–π–¥–µ–Ω–æ {len(problem_stores_df)} –º–∞–≥–∞–∑–∏–Ω–æ–≤ —Å –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ–º > {threshold}%:**"); st.dataframe(problem_stores_df, use_container_width=True)

    st.sidebar.header("üîç –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
    all_stores_list = sorted(processed_df['–º–∞–≥–∞–∑–∏–Ω'].dropna().astype(str).unique())
    problem_stores_list = sorted(problem_stores_df['–º–∞–≥–∞–∑–∏–Ω'].dropna().astype(str).unique())
    analysis_scope = st.sidebar.radio("–û–±–ª–∞—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞:", ('–í—Å–µ –º–∞–≥–∞–∑–∏–Ω—ã', '–¢–æ–ª—å–∫–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ'))
    stores_for_selection = problem_stores_list if analysis_scope == '–¢–æ–ª—å–∫–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ' and problem_stores_list else all_stores_list
    
    if not stores_for_selection:
        st.sidebar.warning("–ù–µ—Ç –º–∞–≥–∞–∑–∏–Ω–æ–≤ –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º.")
    else:
        selected_store = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–∞–≥–∞–∑–∏–Ω:", options=stores_for_selection)
        if selected_store:
            st.markdown("---")
            st.header(f"4. üè™ –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–∞–≥–∞–∑–∏–Ω–∞: '{selected_store}'")
            store_df = processed_df[processed_df['–º–∞–≥–∞–∑–∏–Ω'] == selected_store].copy()

            all_segments = ['–í—Å–µ'] + sorted(store_df['Segment'].dropna().unique()) if 'Segment' in store_df.columns else ['–í—Å–µ']
            all_brands = ['–í—Å–µ'] + sorted(store_df['brend'].dropna().unique()) if 'brend' in store_df.columns else ['–í—Å–µ']
            selected_segment = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Å–µ–≥–º–µ–Ω—Ç", options=all_segments)
            selected_brand = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –±—Ä–µ–Ω–¥", options=all_brands)
            
            filtered_df = store_df.copy()
            if selected_segment != '–í—Å–µ': filtered_df = filtered_df[filtered_df['Segment'] == selected_segment]
            if selected_brand != '–í—Å–µ': filtered_df = filtered_df[filtered_df['brend'] == selected_brand]

            metrics = calculate_metrics(filtered_df)

            st.subheader("üìä –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏")
            col1, col2, col3, col4 = st.columns(4)
            with col1: st.metric("–ü–ª–∞–Ω (—à—Ç.)", f"{int(metrics['total_plan_qty']):,}")
            with col2: st.metric("–§–∞–∫—Ç (—à—Ç.)", f"{int(metrics['total_fact_qty']):,}", delta=f"{int(metrics['qty_deviation']):+,}")
            with col3: st.metric("–ü–ª–∞–Ω (–≥—Ä–Ω.)", f"{metrics['total_plan_money']:,.0f}")
            with col4: st.metric("–§–∞–∫—Ç (–≥—Ä–Ω.)", f"{metrics['total_fact_money']:,.0f}", delta=f"{metrics['money_deviation']:+,.0f}")

            st.subheader("üéØ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–ª–∞–Ω–∞")
            col1, col2 = st.columns(2)
            with col1: st.metric("–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É", f"{metrics['qty_completion']:.1f}%", delta=f"{metrics['qty_completion'] - 100:.1f}%")
            with col2: st.metric("–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏", f"{metrics['money_completion']:.1f}%", delta=f"{metrics['money_completion'] - 100:.1f}%")

            if 'Segment' in store_df.columns and len(all_segments) > 2:
                st.subheader("ü•ß –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
                segment_data = store_df.groupby('Segment').agg(Plan_GRN=('Plan_GRN', 'sum'), Fact_GRN=('Fact_GRN', 'sum')).reset_index()
                col1, col2 = st.columns(2)
                with col1: st.plotly_chart(px.pie(segment_data, values='Plan_GRN', names='Segment', title='–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ü–ª–∞–Ω–∞ (–≥—Ä–Ω)', hole=0.3), use_container_width=True)
                with col2: st.plotly_chart(px.pie(segment_data, values='Fact_GRN', names='Segment', title='–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –§–∞–∫—Ç–∞ (–≥—Ä–Ω)', hole=0.3), use_container_width=True)
            
            if selected_segment != '–í—Å–µ':
                st.subheader(f"‚ö° –°–ø–∏–¥–æ–º–µ—Ç—Ä—ã –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞: '{selected_segment}'")
                #... (–ö–æ–¥ –¥–ª—è —Å–ø–∏–¥–æ–º–µ—Ç—Ä–æ–≤)

            st.subheader("‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π –ø–æ –ø–æ–∑–∏—Ü–∏—è–º")
            discrepancy_df = filtered_df[filtered_df['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_—à—Ç'] != 0].copy()
            
            if not discrepancy_df.empty:
                col1, col2, col3 = st.columns(3)
                with col1: st.metric("–ü–æ–∑–∏—Ü–∏–π —Å —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è–º–∏", len(discrepancy_df))
                with col2: st.metric("–ü–µ—Ä–µ–æ—Å—Ç–∞—Ç–æ–∫", len(discrepancy_df[discrepancy_df['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_—à—Ç'] > 0]))
                with col3: st.metric("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ–∫", len(discrepancy_df[discrepancy_df['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_—à—Ç'] < 0]))

                show_mode = st.radio("–ü–æ–∫–∞–∑–∞—Ç—å:", ('–í—Å–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è', '–¢–æ–ª—å–∫–æ –ø–µ—Ä–µ–æ—Å—Ç–∞—Ç–æ–∫', '–¢–æ–ª—å–∫–æ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ–∫'), horizontal=True)
                if show_mode == '–¢–æ–ª—å–∫–æ –ø–µ—Ä–µ–æ—Å—Ç–∞—Ç–æ–∫': table_df = discrepancy_df[discrepancy_df['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_—à—Ç'] > 0]
                elif show_mode == '–¢–æ–ª—å–∫–æ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ–∫': table_df = discrepancy_df[discrepancy_df['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_—à—Ç'] < 0]
                else: table_df = discrepancy_df

                st.dataframe(table_df, use_container_width=True, height=400)
                
                @st.cache_data
                def to_excel(df_to_export):
                    output = BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        df_to_export.to_excel(writer, index=False, sheet_name='–†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è')
                    processed_data = output.getvalue()
                    return processed_data

                excel_data = to_excel(table_df)
                st.download_button(label="üì• –≠–∫—Å–ø–æ—Ä—Ç –≤ Excel", data=excel_data, file_name=f"—Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è_{selected_store}.xlsx", mime="application/vnd.ms-excel")
            else:
                st.success("üéâ –†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ!")
            
            # ... (–∑–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¢–û–ü—ã –∏ –¥—Ä—É–≥–∏–µ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –±–ª–æ–∫–∏ –∏–∑ –≤–∞—à–µ–≥–æ –∫–æ–¥–∞)

    st.markdown("---")
    st.markdown("<div style='text-align: center; color: #666;'>üìä –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ü–ª–∞–Ω/–§–∞–∫—Ç –ê–Ω–∞–ª–∏–∑ v7.0</div>", unsafe_allow_html=True)
