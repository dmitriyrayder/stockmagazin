# app.py

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
from io import BytesIO
import warnings

# –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã –≤—ã–≤–æ–¥–∞
warnings.filterwarnings('ignore')

# --- 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ---
st.set_page_config(
    page_title="–ü–ª–∞–Ω/–§–∞–∫—Ç –ê–Ω–∞–ª–∏–∑ v8.4 (–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ)",
    page_icon="üîß",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. CSS —Å—Ç–∏–ª–∏ –¥–ª—è –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è ---
st.markdown("""
<style>
    .success-box { background-color: #d4edda; border: 1px solid #c3e6cb; border-radius: 5px; padding: 1rem; margin: 1rem 0; }
    .error-box { background-color: #f8d7da; border: 1px solid #f5c6cb; border-radius: 5px; padding: 1rem; margin: 1rem 0; }
</style>
""", unsafe_allow_html=True)

# --- 3. –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ ---
st.title("üîß –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è –ü–ª–∞–Ω/–§–∞–∫—Ç –∞–Ω–∞–ª–∏–∑–∞ v8.4")
st.info(
    "**–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:** 1Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã ‚Üí 2Ô∏è‚É£ –ù–∞—Å—Ç—Ä–æ–π—Ç–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª–µ–π ‚Üí 3Ô∏è‚É£ –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∞–Ω–∞–ª–∏–∑"
)

# --- 4. –ö–ª—é—á–µ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (—Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏) ---

@st.cache_data
def load_excel_file(file):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç Excel —Ñ–∞–π–ª —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫."""
    try:
        return pd.read_excel(file)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {str(e)}")
        return None

@st.cache_data
def clean_and_prepare_data(df, column_mappings):
    """–û—á–∏—â–∞–µ—Ç –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–ª–æ—Å–∫–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞."""
    if df is None or not column_mappings: return None
    try:
        rename_map = {v: k for k, v in column_mappings.items() if v and v in df.columns}
        cleaned_df = df[list(rename_map.keys())].rename(columns=rename_map).copy()
        
        for col in ['–º–∞–≥–∞–∑–∏–Ω', 'ART', 'Describe', 'MOD', 'brend', 'Segment']:
            if col in cleaned_df.columns:
                cleaned_df[col] = cleaned_df[col].astype(str).str.strip().replace('nan', '')
        
        for col in ['Plan_STUKI', 'Fact_STUKI', 'Plan_GRN', 'Price']:
            if col in cleaned_df.columns:
                cleaned_df[col] = pd.to_numeric(cleaned_df[col], errors='coerce').fillna(0)
        
        if '–º–∞–≥–∞–∑–∏–Ω' in cleaned_df.columns:
            cleaned_df.dropna(subset=['–º–∞–≥–∞–∑–∏–Ω'], inplace=True)
            cleaned_df = cleaned_df[cleaned_df['–º–∞–≥–∞–∑–∏–Ω'] != '']
        if 'ART' in cleaned_df.columns:
            cleaned_df.dropna(subset=['ART'], inplace=True)
            cleaned_df = cleaned_df[cleaned_df['ART'] != '']

        return cleaned_df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
        return None

@st.cache_data
def transform_wide_to_flat(wide_df, id_vars):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —à–∏—Ä–æ–∫–∏–π DataFrame –ø–ª–∞–Ω–∞ –≤ –ø–ª–æ—Å–∫–∏–π."""
    if wide_df is None or not id_vars: return None
    try:
        plan_data_cols = [col for col in wide_df.columns if col not in id_vars]
        
        magazin_cols = sorted([col for col in plan_data_cols if 'magazin' in str(col).lower() or '–º–∞–≥–∞–∑–∏–Ω' in str(col).lower()])
        stuki_cols = sorted([col for col in plan_data_cols if 'stuki' in str(col).lower() or '—à—Ç—É–∫' in str(col).lower()])
        grn_cols = sorted([col for col in plan_data_cols if 'grn' in str(col).lower() or '–≥—Ä–Ω' in str(col).lower() or '—Å—É–º–º' in str(col).lower()])
        
        if not (magazin_cols and stuki_cols and grn_cols):
            raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —à–∏—Ä–æ–∫–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ (–º–∞–≥–∞–∑–∏–Ω, —à—Ç—É–∫–∏, –≥—Ä–Ω).")
        
        min_length = min(len(magazin_cols), len(stuki_cols), len(grn_cols))
        
        flat_parts = []
        for i in range(min_length):
            current_cols = id_vars + [magazin_cols[i], stuki_cols[i], grn_cols[i]]
            part_df = wide_df[current_cols].copy()
            part_df.rename(columns={magazin_cols[i]: '–º–∞–≥–∞–∑–∏–Ω', stuki_cols[i]: 'Plan_STUKI', grn_cols[i]: 'Plan_GRN'}, inplace=True)
            flat_parts.append(part_df)
        
        flat_df = pd.concat(flat_parts, ignore_index=True).dropna(subset=['–º–∞–≥–∞–∑–∏–Ω'])
        flat_df['–º–∞–≥–∞–∑–∏–Ω'] = flat_df['–º–∞–≥–∞–∑–∏–Ω'].astype(str).str.strip()
        flat_df = flat_df[flat_df['–º–∞–≥–∞–∑–∏–Ω'] != '']
        return flat_df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ —à–∏—Ä–æ–∫–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞: {str(e)}")
        return None

def calculate_advanced_metrics(df):
    """–†–∞—Å—á–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."""
    if df is None or df.empty: return {}
    metrics = {
        'total_plan_qty': df['Plan_STUKI'].sum(), 'total_fact_qty': df['Fact_STUKI'].sum(),
        'total_plan_money': df['Plan_GRN'].sum(), 'total_fact_money': df['Fact_GRN'].sum()
    }
    metrics['qty_deviation'] = metrics['total_fact_qty'] - metrics['total_plan_qty']
    metrics['money_deviation'] = metrics['total_fact_money'] - metrics['total_plan_money']
    metrics['qty_completion'] = (metrics['total_fact_qty'] / metrics['total_plan_qty'] * 100) if metrics['total_plan_qty'] else 0
    metrics['money_completion'] = (metrics['total_fact_money'] / metrics['total_plan_money'] * 100) if metrics['total_plan_money'] else 0
    metrics['total_items'] = len(df)
    metrics['items_with_stock'] = len(df[df['Fact_STUKI'] > 0])
    metrics['items_out_of_stock'] = metrics['total_items'] - metrics['items_with_stock']
    return metrics

def convert_df_to_excel(df):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç DataFrame –≤ Excel —Ñ–∞–π–ª –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Å –∞–≤—Ç–æ–ø–æ–¥–±–æ—Ä–æ–º —à–∏—Ä–∏–Ω—ã –∫–æ–ª–æ–Ω–æ–∫."""
    try:
        buffer = BytesIO()
        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='–ê–Ω–∞–ª–∏–∑')
            worksheet = writer.sheets['–ê–Ω–∞–ª–∏–∑']
            for column in worksheet.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    if (value := cell.value) is not None:
                        max_length = max(max_length, len(str(value)))
                worksheet.column_dimensions[column_letter].width = min(max_length + 2, 50)
        buffer.seek(0)
        return buffer.getvalue()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel —Ñ–∞–π–ª–∞: {str(e)}")
        return None

# --- 5. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Session State ---
if 'processed_df' not in st.session_state:
    st.session_state.processed_df = None

# --- 6. –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---

st.header("üìÅ –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤")
col1, col2 = st.columns(2)
plan_file = col1.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª '–ü–ª–∞–Ω'", type=["xlsx", "xls"], key="plan_uploader")
fact_file = col2.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª '–§–∞–∫—Ç'", type=["xlsx", "xls"], key="fact_uploader")

if plan_file and fact_file:
    st.markdown("---")
    st.subheader("–®–∞–≥ 1.1: –°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —á—Ç–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö")
    
    plan_df_original = load_excel_file(plan_file)
    fact_df_original = load_excel_file(fact_file)
    
    initial_plan_rows = len(plan_df_original) if plan_df_original is not None else 0
    initial_fact_rows = len(fact_df_original) if fact_df_original is not None else 0
    
    temp_plan_df = plan_df_original.dropna(how='all') if initial_plan_rows > 0 else pd.DataFrame()
    temp_fact_df = fact_df_original.dropna(how='all') if initial_fact_rows > 0 else pd.DataFrame()
    
    status_data = {
        "–§–∞–π–ª": ["–ü–ª–∞–Ω", "–§–∞–∫—Ç"],
        "–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ": [initial_plan_rows, initial_fact_rows],
        "–°—Ç—Ä–æ–∫ —Å –¥–∞–Ω–Ω—ã–º–∏ (–Ω–µ–ø—É—Å—Ç—ã—Ö)": [len(temp_plan_df), len(temp_fact_df)],
        "–ü—É—Å—Ç—ã—Ö –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö —Å—Ç—Ä–æ–∫": [initial_plan_rows - len(temp_plan_df), initial_fact_rows - len(temp_fact_df)]
    }
    st.dataframe(pd.DataFrame(status_data), use_container_width=True)
    st.markdown("---")
    
    st.header("‚öôÔ∏è –®–∞–≥ 2: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    if plan_df_original is not None and fact_df_original is not None:
        plan_format = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ '–ü–ª–∞–Ω':", ('–ü–ª–æ—Å–∫–∏–π (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π)', '–®–∏—Ä–æ–∫–∏–π (–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π)'), horizontal=True)

        with st.form("processing_form"):
            st.subheader("üîó –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª–µ–π")
            col_map1, col_map2 = st.columns(2)

            with col_map1:
                st.markdown("**üìã –ü–æ–ª—è –∏–∑ —Ñ–∞–π–ª–∞ '–ü–ª–∞–Ω'**")
                if plan_format == '–®–∏—Ä–æ–∫–∏–π (–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π)':
                    id_vars = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–æ–ª—è —Ç–æ–≤–∞—Ä–∞", options=plan_df_original.columns.tolist(), default=[c for c in ['ART', 'Describe', 'MOD', 'Price', 'brend', 'Segment'] if c in plan_df_original.columns], help="–ü–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ –æ–ø–∏—Å—ã–≤–∞—é—Ç —Ç–æ–≤–∞—Ä (–ù–ï –º–∞–≥–∞–∑–∏–Ω—ã, –ù–ï —à—Ç—É–∫–∏, –ù–ï —Å—É–º–º—ã)")
                    plan_mappings = {}
                else:
                    id_vars = []
                    PLAN_FIELDS = {'–º–∞–≥–∞–∑–∏–Ω': '–ú–∞–≥–∞–∑–∏–Ω', 'ART': '–ê—Ä—Ç–∏–∫—É–ª', 'Describe': '–û–ø–∏—Å–∞–Ω–∏–µ', 'MOD': '–ú–æ–¥–µ–ª—å', 'Price': '–¶–µ–Ω–∞', 'brend': '–ë—Ä–µ–Ω–¥', 'Segment': '–°–µ–≥–º–µ–Ω—Ç', 'Plan_STUKI': '–ü–ª–∞–Ω (—à—Ç.)', 'Plan_GRN': '–ü–ª–∞–Ω (—Å—É–º–º–∞)'}
                    plan_cols = [''] + plan_df_original.columns.tolist()
                    plan_mappings = {internal: st.selectbox(f"{'‚≠ê ' if internal in ['–º–∞–≥–∞–∑–∏–Ω', 'ART', 'Plan_STUKI', 'Plan_GRN'] else ''}{display}", plan_cols, key=f'plan_{internal}') for internal, display in PLAN_FIELDS.items()}
            
            with col_map2:
                st.markdown("**üìã –ü–æ–ª—è –∏–∑ —Ñ–∞–π–ª–∞ '–§–∞–∫—Ç'**")
                FACT_FIELDS = {'–º–∞–≥–∞–∑–∏–Ω': '–ú–∞–≥–∞–∑–∏–Ω', 'ART': '–ê—Ä—Ç–∏–∫—É–ª', 'Describe': '–û–ø–∏—Å–∞–Ω–∏–µ', 'MOD': '–ú–æ–¥–µ–ª—å', 'Fact_STUKI': '–§–∞–∫—Ç (—à—Ç.)'}
                fact_cols = [''] + fact_df_original.columns.tolist()
                fact_mappings = {internal: st.selectbox(f"{'‚≠ê ' if internal in ['–º–∞–≥–∞–∑–∏–Ω', 'ART', 'Fact_STUKI'] else ''}{display}", fact_cols, key=f'fact_{internal}') for internal, display in FACT_FIELDS.items()}

            submitted = st.form_submit_button("üöÄ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑", type="primary", use_container_width=True)

        if submitted:
            with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö..."):
                try:
                    if plan_format == '–®–∏—Ä–æ–∫–∏–π (–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π)':
                        if not id_vars: raise ValueError("–î–ª—è —à–∏—Ä–æ–∫–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–±—Ä–∞—Ç—å –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–æ–ª—è.")
                        plan_df = transform_wide_to_flat(plan_df_original, id_vars)
                    else:
                        if not all(plan_mappings.get(f) for f in ['–º–∞–≥–∞–∑–∏–Ω', 'ART', 'Plan_STUKI', 'Plan_GRN']): raise ValueError("–ù–µ –≤—ã–±—Ä–∞–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–ª—è '–ü–ª–∞–Ω–∞'.")
                        plan_df = clean_and_prepare_data(plan_df_original, plan_mappings)
                    
                    if not all(fact_mappings.get(f) for f in ['–º–∞–≥–∞–∑–∏–Ω', 'ART', 'Fact_STUKI']): raise ValueError("–ù–µ –≤—ã–±—Ä–∞–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–ª—è '–§–∞–∫—Ç–∞'.")
                    fact_df = clean_and_prepare_data(fact_df_original, fact_mappings)

                    if plan_df is None or fact_df is None: raise ValueError("–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.")

                    merge_keys = ['–º–∞–≥–∞–∑–∏–Ω', 'ART']
                    for key in ['Describe', 'MOD']:
                        if key in plan_df.columns and key in fact_df.columns: merge_keys.append(key)
                    
                    plan_cols_to_merge = [col for col in plan_df.columns if col not in ['Fact_STUKI']]
                    fact_cols_to_merge = [col for col in merge_keys + ['Fact_STUKI'] if col in fact_df.columns]
                    merged_df = pd.merge(plan_df[plan_cols_to_merge], fact_df[fact_cols_to_merge], on=merge_keys, how='outer')

                    for col in ['Plan_STUKI', 'Fact_STUKI', 'Plan_GRN', 'Price']:
                        if col in merged_df.columns:
                            merged_df[col] = merged_df[col].fillna(0)
                    
                    merged_df['Fact_GRN'] = (merged_df['Fact_STUKI'] * merged_df['Price']).fillna(0)
                    merged_df['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_—à—Ç'] = merged_df['Fact_STUKI'] - merged_df['Plan_STUKI']
                    merged_df['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_–≥—Ä–Ω'] = merged_df['Fact_GRN'] - merged_df['Plan_GRN']
                    merged_df['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_%_—à—Ç'] = np.where(merged_df['Plan_STUKI'] != 0, (merged_df['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_—à—Ç'] / merged_df['Plan_STUKI']) * 100, np.where(merged_df['Fact_STUKI'] != 0, 999, 0))
                    merged_df['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_%_–≥—Ä–Ω'] = np.where(merged_df['Plan_GRN'] != 0, (merged_df['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_–≥—Ä–Ω'] / merged_df['Plan_GRN']) * 100, np.where(merged_df['Fact_GRN'] != 0, 999, 0))
                    
                    st.session_state.processed_df = merged_df
                    st.markdown(f"""<div class="success-box"><h4>‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!</h4><p><strong>–ò—Ç–æ–≥–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞:</strong> {len(merged_df)} –∑–∞–ø–∏—Å–µ–π</p><p><strong>–ú–∞–≥–∞–∑–∏–Ω–æ–≤:</strong> {merged_df['–º–∞–≥–∞–∑–∏–Ω'].nunique()}</p><p><strong>–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤:</strong> {merged_df['ART'].nunique()}</p></div>""", unsafe_allow_html=True)
                except Exception as e:
                    st.session_state.processed_df = None
                    st.markdown(f"""<div class="error-box"><h4>‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ</h4><p>{str(e)}</p></div>""", unsafe_allow_html=True)

# --- 7. –ë–ª–æ–∫ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ ---
if st.session_state.processed_df is not None:
    processed_df = st.session_state.processed_df
    all_stores_list = sorted(processed_df['–º–∞–≥–∞–∑–∏–Ω'].dropna().unique())

    st.header("üìä –®–∞–≥ 3: –°–≤–æ–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞–º")
    store_summary = processed_df.groupby('–º–∞–≥–∞–∑–∏–Ω').agg({'Plan_STUKI': 'sum', 'Fact_STUKI': 'sum', 'Plan_GRN': 'sum', 'Fact_GRN': 'sum'}).reset_index()
    store_summary['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_—à—Ç'] = store_summary['Fact_STUKI'] - store_summary['Plan_STUKI']
    store_summary['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_–≥—Ä–Ω'] = store_summary['Fact_GRN'] - store_summary['Plan_GRN']
    store_summary['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_%_—à—Ç_abs'] = np.where(store_summary['Plan_STUKI'] != 0, abs(store_summary['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_—à—Ç']) / store_summary['Plan_STUKI'] * 100, 999)

    col1, col2 = st.columns([3, 1])
    threshold = col1.slider("–ü–æ–∫–∞–∑–∞—Ç—å –º–∞–≥–∞–∑–∏–Ω—ã —Å –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ–º –≤ —à—Ç—É–∫–∞—Ö –±–æ–ª—å—à–µ (%)", 0, 100, 10, 5)
    sort_by = col2.selectbox("–°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ:", ['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_%_—à—Ç_abs', '–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_—à—Ç', '–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_–≥—Ä–Ω'], index=0, format_func=lambda x: {'–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_%_—à—Ç_abs': '–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ %', '–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_—à—Ç': '–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ —à—Ç.', '–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_–≥—Ä–Ω': '–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –≥—Ä–Ω.'}.get(x))

    problem_stores_df = store_summary[store_summary['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_%_—à—Ç_abs'] > threshold].sort_values(sort_by, ascending=False)
    
    if not problem_stores_df.empty:
        st.success(f"üéØ –ù–∞–π–¥–µ–Ω–æ {len(problem_stores_df)} –º–∞–≥–∞–∑–∏–Ω–æ–≤ —Å –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ–º > {threshold}%")
        fig = px.bar(problem_stores_df.head(20), x='–º–∞–≥–∞–∑–∏–Ω', y='–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_%_—à—Ç_abs', title=f'–¢–û–ü-20 –º–∞–≥–∞–∑–∏–Ω–æ–≤ –ø–æ –∞–±—Å–æ–ª—é—Ç–Ω–æ–º—É –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—é (> {threshold}%)', color='–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_%_—à—Ç_abs', color_continuous_scale='Reds', labels={'–º–∞–≥–∞–∑–∏–Ω': '–ú–∞–≥–∞–∑–∏–Ω', '–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_%_—à—Ç_abs': '–ê–±—Å–æ–ª—é—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ, %'})
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info(f"üéâ –û—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞! –ù–µ—Ç –º–∞–≥–∞–∑–∏–Ω–æ–≤ —Å –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ–º –±–æ–ª—å—à–µ {threshold}%")

    st.markdown("---")
    st.header("üìà –®–∞–≥ 3.1: –ê–Ω–∞–ª–∏–∑ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º")
    selected_store_for_segment = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–∞–≥–∞–∑–∏–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º:", all_stores_list, key="segment_store_selector")

    if selected_store_for_segment and 'Segment' in processed_df.columns:
        # –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê
        full_segment_summary = processed_df.groupby(['–º–∞–≥–∞–∑–∏–Ω', 'Segment']).agg(
            Plan_STUKI=('Plan_STUKI', 'sum'), Fact_STUKI=('Fact_STUKI', 'sum'),
            Plan_GRN=('Plan_GRN', 'sum'), Fact_GRN=('Fact_GRN', 'sum')
        ).reset_index()
        
        segment_summary = full_segment_summary[full_segment_summary['–º–∞–≥–∞–∑–∏–Ω'] == selected_store_for_segment].copy()

        if not segment_summary.empty:
            segment_summary['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_—à—Ç'] = segment_summary['Fact_STUKI'] - segment_summary['Plan_STUKI']
            segment_summary['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_–≥—Ä–Ω'] = segment_summary['Fact_GRN'] - segment_summary['Plan_GRN']
            segment_summary['–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ_–ø–ª–∞–Ω–∞_%'] = np.where(segment_summary['Plan_STUKI'] > 0, (segment_summary['Fact_STUKI'] / segment_summary['Plan_STUKI']) * 100, np.where(segment_summary['Fact_STUKI'] > 0, 999, 0))
            
            st.dataframe(segment_summary.drop(columns=['–º–∞–≥–∞–∑–∏–Ω']).style.format({
                'Plan_STUKI': '{:,.0f}', 'Fact_STUKI': '{:,.0f}', '–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_—à—Ç': '{:+,_d}',
                'Plan_GRN': '{:,.0f}', 'Fact_GRN': '{:,.0f}', '–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_–≥—Ä–Ω': '{:+,_d}',
                '–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ_–ø–ª–∞–Ω–∞_%': '{:.1f}%'
            }), use_container_width=True)
        else:
            st.info(f"–î–ª—è –º–∞–≥–∞–∑–∏–Ω–∞ ¬´{selected_store_for_segment}¬ª –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º.")
    elif 'Segment' not in processed_df.columns:
        st.warning("–ö–æ–ª–æ–Ω–∫–∞ 'Segment' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ê–Ω–∞–ª–∏–∑ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")

    st.sidebar.header("üîç –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
    problem_stores_list = sorted(problem_stores_df['–º–∞–≥–∞–∑–∏–Ω'].unique())
    analysis_scope = st.sidebar.radio("–û–±–ª–∞—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞:", ('–¢–æ–ª—å–∫–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ', '–í—Å–µ –º–∞–≥–∞–∑–∏–Ω—ã'), horizontal=True)
    stores_for_selection = problem_stores_list if analysis_scope == '–¢–æ–ª—å–∫–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ' and problem_stores_list else all_stores_list

    if stores_for_selection:
        selected_store = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–∞–≥–∞–∑–∏–Ω:", options=stores_for_selection, key="detail_store_selector")
        if selected_store:
            st.markdown("---")
            st.header(f"üè™ –®–∞–≥ 4: –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–∞–≥–∞–∑–∏–Ω–∞ ¬´{selected_store}¬ª")
            
            store_df = processed_df[processed_df['–º–∞–≥–∞–∑–∏–Ω'] == selected_store].copy()
            
            col1, col2 = st.columns(2)
            all_segments = ['–í—Å–µ'] + sorted([s for s in store_df['Segment'].dropna().unique() if s]) if 'Segment' in store_df else ['–í—Å–µ']
            all_brands = ['–í—Å–µ'] + sorted([b for b in store_df['brend'].dropna().unique() if b]) if 'brend' in store_df else ['–í—Å–µ']
            selected_segment = col1.selectbox("–§–∏–ª—å—Ç—Ä –ø–æ —Å–µ–≥–º–µ–Ω—Ç—É:", all_segments)
            selected_brand = col2.selectbox("–§–∏–ª—å—Ç—Ä –ø–æ –±—Ä–µ–Ω–¥—É:", all_brands)
            
            filtered_df = store_df.copy()
            if selected_segment != '–í—Å–µ': filtered_df = filtered_df[filtered_df['Segment'] == selected_segment]
            if selected_brand != '–í—Å–µ': filtered_df = filtered_df[filtered_df['brend'] == selected_brand]

            metrics = calculate_advanced_metrics(filtered_df)
            st.subheader("üìà –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏")
            m1, m2, m3, m4 = st.columns(4)
            m1.metric("–ü–ª–∞–Ω (—à—Ç.)", f"{int(metrics.get('total_plan_qty', 0)):,}")
            m1.metric("–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ —à—Ç. (%)", f"{metrics.get('qty_completion', 0):.1f}%", f"{metrics.get('qty_completion', 0) - 100:.1f}%")
            m2.metric("–§–∞–∫—Ç (—à—Ç.)", f"{int(metrics.get('total_fact_qty', 0)):,}", f"{int(metrics.get('qty_deviation', 0)):+,}")
            m2.metric("–ù–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏", f"{metrics.get('items_out_of_stock', 0):,}", delta_color="inverse")
            m3.metric("–ü–ª–∞–Ω (–≥—Ä–Ω)", f"{metrics.get('total_plan_money', 0):,.0f}")
            m3.metric("–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ –≥—Ä–Ω (%)", f"{metrics.get('money_completion', 0):.1f}%", f"{metrics.get('money_completion', 0) - 100:.1f}%")
            m4.metric("–§–∞–∫—Ç (–≥—Ä–Ω)", f"{metrics.get('total_fact_money', 0):,.0f}", f"{metrics.get('money_deviation', 0):+,.0f}")
            m4.metric("–¢–æ–≤–∞—Ä–æ–≤ –≤ –Ω–∞–ª–∏—á–∏–∏", f"{metrics.get('items_with_stock', 0):,}", f"–∏–∑ {metrics.get('total_items', 0)}")

            if not filtered_df.empty:
                st.subheader("üìë –î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–æ —Ç–æ–≤–∞—Ä–∞–º (–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –ø–æ –≤–µ–ª–∏—á–∏–Ω–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è)")
                display_cols = ['ART', 'Describe', 'Plan_STUKI', 'Fact_STUKI', '–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_—à—Ç', '–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_%_—à—Ç', 'Plan_GRN', 'Fact_GRN', '–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_–≥—Ä–Ω']
                
                filtered_df['abs_deviation_qty'] = filtered_df['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_—à—Ç'].abs()
                df_to_show = filtered_df.sort_values('abs_deviation_qty', ascending=False)
                st.dataframe(df_to_show[[c for c in display_cols if c in df_to_show]], use_container_width=True, height=500)
            else:
                st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º.")
                
    st.markdown("---")
    st.header("üíæ –®–∞–≥ 5: –°–∫–∞—á–∞—Ç—å –æ—Ç—á–µ—Ç")
    excel_data = convert_df_to_excel(processed_df)
    if excel_data:
        st.download_button(label="üì• –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –≤ Excel", data=excel_data, file_name=f"plan_fact_analysis_{datetime.now().strftime('%Y-%m-%d')}.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True)
